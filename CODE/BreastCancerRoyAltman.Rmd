---
title: "Risk-Evaluation: Breast Cancer Royston-Altman"
author: "Jose Tamez"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    toc: yes
    fig_caption: yes
    number_sections: yes
    fig_crop: no
  html_document: 
    toc: yes
    fig_caption: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Evaluation of RISK survival models

This document highlights the use of

-   RRPlot(),

-   CoxRiskCalibration(), and

-   CalibrationProbPoissonRisk(),

for the evaluation (RRPlot), and calibration of cox models (CoxRiskCalibration) or logistic models (CalibrationProbPoissonRisk) of survival data.

Furthermore, it can be used to evaluate any Risk index that reruns the probability of a future event on external data-set.

This document will use the survival::rotterdam, and survival::gbsg data-sets to train and predict the risk of cancer recurrence after surgery. Both Cox and Logistic models will be trained and evaluated.

Here are some sample plots returned by the evaluated functions:

## The libraries

```{r}
library(survival)
library(FRESA.CAD)
#source("~/GitHub/FRESA.CAD/R/RRPlot.R")
#source("~/GitHub/FRESA.CAD/R/PoissonEventRiskCalibration.R")
op <- par(no.readonly = TRUE)
pander::panderOptions('digits', 3)
#pander::panderOptions('table.split.table', 400)
pander::panderOptions('keep.trailing.zeros',TRUE)

```

## Breast Cancer Royston-Altman data

### data(gbsg, package="survival") and data(rotterdam, package="survival")

```{r results = "asis"}
gbsgdata <- gbsg
rownames(gbsgdata) <- gbsgdata$pid
gbsgdata$pid <- NULL

odata <-rotterdam
rownames(odata) <- odata$pid
odata$pid <- NULL
odata$rfstime <- odata$rtime
odata$status <- odata$recur
odata$rtime <- NULL
odata$recur <- NULL

odata <- odata[,colnames(odata) %in% colnames(gbsgdata)]

odata$size <- 10*(odata$size=="<=20") + 
  35*(odata$size=="20-50") + 
  60*(odata$size==">50")

data <- as.data.frame(model.matrix(Surv(rfstime,status)~.*.,odata))

data$`(Intercept)` <- NULL

dataBrestCancerTrain <- cbind(time=odata[rownames(data),"rfstime"],status=odata[rownames(data),"status"],data)

colnames(dataBrestCancerTrain) <-str_replace_all(colnames(dataBrestCancerTrain),":","_")
colnames(dataBrestCancerTrain) <-str_replace_all(colnames(dataBrestCancerTrain)," ","")
colnames(dataBrestCancerTrain) <-str_replace_all(colnames(dataBrestCancerTrain),"\\.","_")
colnames(dataBrestCancerTrain) <-str_replace_all(colnames(dataBrestCancerTrain),"-","_")
colnames(dataBrestCancerTrain) <-str_replace_all(colnames(dataBrestCancerTrain),">","_")
dataBrestCancerTrain$time <- dataBrestCancerTrain$time/365 ## To years


pander::pander(table(odata[rownames(data),"status"]),caption="rotterdam")


```

### data(gbsg, package="survival") data conditioning

```{r results = "asis"}

gbsgdata <- gbsgdata[,colnames(odata)]
data <- as.data.frame(model.matrix(Surv(rfstime,status)~.*.,gbsgdata))

data$`(Intercept)` <- NULL

dataBrestCancerTest <- cbind(time=gbsgdata[rownames(data),"rfstime"],status=gbsgdata[rownames(data),"status"],data)

colnames(dataBrestCancerTest) <-str_replace_all(colnames(dataBrestCancerTest),":","_")
colnames(dataBrestCancerTest) <-str_replace_all(colnames(dataBrestCancerTest)," ","")
colnames(dataBrestCancerTest) <-str_replace_all(colnames(dataBrestCancerTest),"\\.","_")
colnames(dataBrestCancerTest) <-str_replace_all(colnames(dataBrestCancerTest),"-","_")
colnames(dataBrestCancerTest) <-str_replace_all(colnames(dataBrestCancerTest),">","_")
dataBrestCancerTest$time <- dataBrestCancerTest$time/365

pander::pander(table(odata[rownames(data),"status"]), caption="gbsg")


```

## Cox Modeling

```{r results = "asis"}

ml <- BSWiMS.model(Surv(time,status)~.,data=dataBrestCancerTrain,loops=1,NumberofRepeats = 5)
sm <- summary(ml)
pander::pander(sm$coefficients)
```

## Cox Model Performance

Here we evaluate the model using the RRPlot() function.

### The evaluation of the raw Cox model with RRPlot()

Here we will use the predicted event probability assuming a baseline hazard for events withing 5 years

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

timeinterval <- 5 # Five years

h0 <- sum(dataBrestCancerTrain$status & dataBrestCancerTrain$time <= timeinterval)
h0 <- h0/sum((dataBrestCancerTrain$time > timeinterval) | (dataBrestCancerTrain$status==1))

pander::pander(t(c(h0=h0,timeinterval=timeinterval)),caption="Initial Parameters")

index <- predict(ml,dataBrestCancerTrain)
rdata <- cbind(dataBrestCancerTrain$status,ppoisGzero(index,h0))

rrAnalysisTrain <- RRPlot(rdata,atProb=c(0.90,0.80),
                     timetoEvent=dataBrestCancerTrain$time,
                     title="Train: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)


```

As we can see the Observed probability as well as the Time vs. Events are not calibrated.

### Uncalibrated Performance Report

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisTrain$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisTrain$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisTrain$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysisTrain$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```

### Cox Calibration

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
op <- par(no.readonly = TRUE)


calprob <- CoxRiskCalibration(ml,dataBrestCancerTrain,"status","time")


pander::pander(c(h0=calprob$h0,
                 Gain=calprob$hazardGain,
                 DeltaTime=calprob$timeInterval),
               caption="Cox Calibration Parameters")

```

### The RRplot() of the calibrated model

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
h0 <- calprob$h0
timeinterval <- calprob$timeInterval;

rdata <- cbind(dataBrestCancerTrain$status,calprob$prob)


rrAnalysisTrain <- RRPlot(rdata,atProb=c(0.90,0.80),
                     timetoEvent=dataBrestCancerTrain$time,
                     title="Cal. Train: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)

```

### Calibrated Train Performance

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisTrain$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisTrain$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisTrain$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysisTrain$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```

## Performance on the external data set

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

index <- predict(ml,dataBrestCancerTest)
pp <- predictionStats_binary(cbind(dataBrestCancerTest$status,index),plotname="Breast Cancer")
par(op)


prob <- ppoisGzero(index,h0)
rdata <- cbind(dataBrestCancerTest$status,prob)
rrCoxTestAnalysis <- RRPlot(rdata,atThr=rrAnalysisTrain$thr_atP,
                     timetoEvent=dataBrestCancerTest$time,
                     title="Test: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)

par(op)

```

### External Data Report

```{r results = "asis"}
pander::pander(t(rrCoxTestAnalysis$keyPoints),caption="Threshold values")
pander::pander(t(rrCoxTestAnalysis$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrCoxTestAnalysis$c.index,caption="C. Index")
pander::pander(t(rrCoxTestAnalysis$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrCoxTestAnalysis$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrCoxTestAnalysis$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrCoxTestAnalysis$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrCoxTestAnalysis$RR_atP),caption="Risk Ratio")
pander::pander(rrCoxTestAnalysis$surdif,caption="Logrank test")

```

### Calibrating the index on the test data

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

calprob <- CoxRiskCalibration(ml,dataBrestCancerTest,"status","time")

pander::pander(c(h0=calprob$h0,
                 Gain=calprob$hazardGain,
                 DeltaTime=calprob$timeInterval),
               caption="Cox Calibration Parameters")

rdata <- cbind(dataBrestCancerTest$status,calprob$prob)

rrAnalysis <- RRPlot(rdata,atProb=c(0.90,0.80),
                     timetoEvent=dataBrestCancerTest$time,
                     title="Cal. Test: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=calprob$timeInterval)

```

### After Calibration Report

```{r results = "asis"}

pander::pander(t(rrAnalysis$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysis$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrAnalysis$c.index,caption="C. Index")
pander::pander(t(rrAnalysis$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysis$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysis$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysis$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysis$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysis$surdif,caption="Logrank test")

```

## Logistic Model

Here we train a logistic model on the same data set

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

## Only label subjects that present event withing five years

dataBrestCancerR <- subset(dataBrestCancerTrain, time>=5 | status==1)
dataBrestCancerR$status <- dataBrestCancerR$status * (dataBrestCancerR$time < 5)
dataBrestCancerR$time <- NULL

#ml <- BSWiMS.model(status~1,data=dataBrestCancerR,loops=20,NumberofRepeats = 5)
mlog <- BSWiMS.model(status~1,data=dataBrestCancerR,loops=1,NumberofRepeats = 5)
sm <- summary(mlog)
pander::pander(sm$coefficients)


```

## Logistic Model Performance

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
op <- par(no.readonly = TRUE)


cprob <- predict(mlog,dataBrestCancerTrain)

rdata <- cbind(dataBrestCancerTrain$status,cprob)
rrAnalysisTrain <- RRPlot(rdata,atProb=c(0.90,0.80),
                     timetoEvent=dataBrestCancerTrain$time,
                     title="Logistic Train: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=5.0)
par(op)



```

### Training Report

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrAnalysisTrain$c.index,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysisTrain$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```

### Results on the validation set using Logistic model

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
pre <- predict(mlog,dataBrestCancerTest)
rdata <- cbind(dataBrestCancerTest$status,pre)

rrAnalysis <- RRPlot(rdata,atThr=rrAnalysisTrain$thr_atP,
                     timetoEvent=dataBrestCancerTest$time,
                     title="Logistic Test: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=5)

par(op)

```

### Validation Report

```{r results = "asis"}

pander::pander(t(rrAnalysis$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysis$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrAnalysis$c.index,caption="C. Index")
pander::pander(t(rrAnalysis$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysis$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysis$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysis$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysis$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysis$surdif,caption="Logrank test")

```

## Logistic Model Poisson Calibration

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

riskdata <- cbind(dataBrestCancerTrain$status,predict(mlog,dataBrestCancerTrain,type="prob"),dataBrestCancerTrain$time)
calprob <- CalibrationProbPoissonRisk(riskdata)

pander::pander(c(h0=calprob$h0,
                 Gain=calprob$hazardGain,
                 DeltaTime=calprob$timeInterval),
               caption="Logistic Calibration Parameters")

timeinterval <- calprob$timeInterval;
gain <- calprob$hazardGain

rdata <- cbind(dataBrestCancerTrain$status,calprob$prob)


rrAnalysisTrain <- RRPlot(rdata,atProb=c(0.90,0.80),
                     timetoEvent=dataBrestCancerTrain$time,
                     title="Cal. Logistic Train: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)


par(op)


```

### Report of the calibrated logistic: training

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrAnalysisTrain$c.index,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysisTrain$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
probLog <- predict(mlog,dataBrestCancerTest)
aprob <- adjustProb(probLog,gain)

rdata <- cbind(dataBrestCancerTest$status,aprob)
rrAnalysisTestLogistic <- RRPlot(rdata,atThr=rrAnalysisTrain$thr_atP,
                     timetoEvent=dataBrestCancerTest$time,
                     title="Cal. Logistic Test: Breast Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)
par(op)

```

### Report of the calibrated validation

```{r results = "asis"}

pander::pander(t(rrAnalysisTestLogistic$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTestLogistic$OERatio$estimate),caption="O/E Ratio")
pander::pander(rrAnalysisTestLogistic$c.index,caption="C. Index")
pander::pander(t(rrAnalysisTestLogistic$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTestLogistic$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTestLogistic$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTestLogistic$thr_atP),caption="Probability Thresholds")
pander::pander(t(rrAnalysisTestLogistic$RR_atP),caption="Risk Ratio")
pander::pander(rrAnalysisTestLogistic$surdif,caption="Logrank test")

```

## Comparing the COX and Logistic Models on the Independent Data

```{r results = "asis", warning = FALSE , dpi=600, fig.height= 4.0, fig.width= 8.0}

pander::pander(t(rrCoxTestAnalysis$OAcum95ci))
pander::pander(t(rrAnalysisTestLogistic$OAcum95ci))

pander::pander(t(rrCoxTestAnalysis$OE95ci))
pander::pander(t(rrAnalysisTestLogistic$OE95ci))
maxobs <- sum(dataBrestCancerTest$status)

par(mfrow=c(1,2),cex=0.75)

plot(rrCoxTestAnalysis$CumulativeOvs[,1:2],type="l",lty=1,
     main="Cumulative Probability",
     xlab="Observed",
     ylab="Cumulative Probability",
     ylim=c(0,maxobs),
     xlim=c(0,maxobs))
lines(rrAnalysisTestLogistic$CumulativeOvs[,1:2],lty=2,col="red")
lines(x=c(0,maxobs),y=c(0,maxobs),lty=3,col="gray")
legend("topleft",legend = c("Cox","Logistic","Ideal"),
       col=c("black","red","gray"),
       lty=c(1,2,3),
       cex=0.75
)


plot(rrCoxTestAnalysis$CumulativeOvs$Observed,
     rrCoxTestAnalysis$CumulativeOvs$Cumulative-
       rrCoxTestAnalysis$CumulativeOvs$Observed,
     main="Cumulative Risk Difference",
     xlab="Observed",
     ylab="Cumulative Risk - Observed",
     type="l",
     lty=1)
lines(rrAnalysisTestLogistic$CumulativeOvs$Observed,
     rrAnalysisTestLogistic$CumulativeOvs$Cumulative-
       rrAnalysisTestLogistic$CumulativeOvs$Observed,
     lty=2,
     col="red")
legend("topleft",legend = c("Cox","Logistic"),
       col=c("black","red"),
       lty=c(1,2),
       cex=0.75
)

plot(rrCoxTestAnalysis$OEData[,2:3],type="l",lty=1,
     main="Expected over Time",
     xlab="Observed",
     ylab="Expected",
     ylim=c(0,maxobs),
     xlim=c(0,maxobs))
lines(rrAnalysisTestLogistic$OEData[,2:3],lty=2,col="red")
lines(x=c(0,maxobs),y=c(0,maxobs),lty=3,col="gray")
legend("topleft",legend = c("Cox","Logistic","Ideal"),
       col=c("black","red","gray"),
       lty=c(1,2,3),
       cex=0.75
)

plot(rrCoxTestAnalysis$OEData$Observed,
     rrCoxTestAnalysis$OEData$Expected-
       rrCoxTestAnalysis$OEData$Observed,
     main="Expected vs Observed Difference",
     xlab="Observed",
     ylab="Cumulative - Observed",
     type="l",
     lty=1)
lines(rrAnalysisTestLogistic$OEData$Observed,
     rrAnalysisTestLogistic$OEData$Expected-
       rrAnalysisTestLogistic$OEData$Observed,
     lty=2,col="red")

legend("bottomleft",legend = c("Cox","Logistic"),
       col=c("black","red"),
       lty=c(1,2),
       cex=0.75
)

par(op)

```

