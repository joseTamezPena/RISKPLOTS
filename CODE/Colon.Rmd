---
title: "Colon Cancer"
author: "Jose Tamez"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    fig_caption: yes
  pdf_document: 
    toc: yes
    fig_caption: yes
    fig_crop: no
    number_sections: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# RRPlot and the Colon data set

### Libraries
```{r}
library(survival)
library(FRESA.CAD)
op <- par(no.readonly = TRUE)
pander::panderOptions('digits', 3)
pander::panderOptions('table.split.table', 400)
pander::panderOptions('keep.trailing.zeros',TRUE)

source("C:/Users/jtame/Documents/GitHub/RISKPLOTS/CODE/auxplots.R")

```
## The data set

```{r results = "asis"}
data(cancer)
colon <- subset(colon,etype==1)
colon$etype <- NULL
rownames(colon) <- colon$id
colon$id <- NULL
colon <- colon[complete.cases(colon),]
time <- colon$time
status <- colon$status
data <- colon
data$time <- NULL
data$study <- NULL
table(data$status)
dataColon <- as.data.frame(model.matrix(status~.*age,data))
dataColon$`(Intercept)` <- NULL
dataColon$time <- time/365
dataColon$status <- status
colnames(dataColon) <-str_replace_all(colnames(dataColon),":","_")
colnames(dataColon) <-str_replace_all(colnames(dataColon),"\\.","_")
colnames(dataColon) <-str_replace_all(colnames(dataColon),"\\+","_")
data <- NULL

trainsamples <- sample(nrow(dataColon),0.7*nrow(dataColon))
dataColonTrain <- dataColon[trainsamples,]
dataColonTest <- dataColon[-trainsamples,]


pander::pander(table(dataColonTrain$status))
pander::pander(table(dataColonTest$status))


```

## Modeling
```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
ml <- BSWiMS.model(Surv(time,status)~1,data=dataColonTrain,loops=20,NumberofRepeats = 5)
sm <- summary(ml)
pander::pander(sm$coefficients)
```

## Cox Model Performance

Here we evaluate the model using the RRPlot() function.

### The evaluation of the raw Cox model with RRPlot()

Here we will use the predicted event probability assuming a baseline hazard for events withing 5 years

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

index <- predict(ml,dataColonTrain)
timeinterval <- round(2*mean(subset(dataColonTrain,status==1)$time),0)
timeinterval <- 2

h0 <- sum(dataColonTrain$status & dataColonTrain$time <= timeinterval)
h0 <- h0/sum((dataColonTrain$time > timeinterval) | (dataColonTrain$status==1))

rdata <- cbind(dataColonTrain$status,ppoisGzero(index,h0))

rrAnalysisTrain <- RRPlot(rdata,atRate=c(0.90,0.80),
                     timetoEvent=dataColonTrain$time,
                     title="Raw Train: Colon Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=timeinterval)

```

### By Risk Categories
```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

obsexp <- rrAnalysisTrain$OERatio$atThrEstimates

expObs(obsexp,"Train: Expected vs. Observed")

pander::pander(obsexp)

```



### Time to Event Analysis

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
rrAnalysisdata <- rrAnalysisTrain

pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime,rrAnalysisdata$timetoEventData$expectedTime,paired = TRUE))
highrisk <- rrAnalysisdata$timetoEventData$class == 2
pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime[highrisk],rrAnalysisdata$timetoEventData$expectedTime[highrisk],paired = TRUE))

timesdata <- expObsTime(rrAnalysisdata,title="Train: Expected vs Observed")
pander::pander(timesdata)

```

### Uncalibrated Performance Report

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisTrain$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisTrain$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisTrain$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```



### Cox Calibration

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
op <- par(no.readonly = TRUE)


calprob <- CoxRiskCalibration(ml,dataColonTrain,"status","time")

pander::pander(c(h0=calprob$h0,
                 Gain=calprob$hazardGain,
                 TimeInterval=calprob$timeInterval),
               caption="Cox Calibration Parameters")

```



### The RRplot() of the calibrated model

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

rCaldata <- cbind(dataColonTrain$status,calprob$prob)


rrAnalysisCalTrain <- RRPlot(rCaldata,atRate=c(0.90,0.80),
                     timetoEvent=dataColonTrain$time,
                     title="Calibrated Train: Colon",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=calprob$timeInterval)

```


### By Risk Categories
```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

obsexp <- rrAnalysisCalTrain$OERatio$atThrEstimates

expObs(obsexp,"Cal: Expected vs. Observed")

pander::pander(obsexp)

```



### Time to Event Analysis

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
rrAnalysisdata <- rrAnalysisCalTrain

pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime,rrAnalysisdata$timetoEventData$expectedTime,paired = TRUE))
highrisk <- rrAnalysisdata$timetoEventData$class == 2
pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime[highrisk],rrAnalysisdata$timetoEventData$expectedTime[highrisk],paired = TRUE))

timesdata <- expObsTime(rrAnalysisdata,title="Cal: Expected vs Observed")
pander::pander(timesdata)

```

### Calibrated Train Performance

```{r results = "asis"}

pander::pander(t(rrAnalysisTrain$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTrain$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisTrain$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisTrain$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisTrain$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
pander::pander(rrAnalysisTrain$surdif,caption="Logrank test")

```

### Evaluating on the test set

The calibrated h0 and timeinterval were estimated on the training set

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

index <- predict(ml,dataColonTest)
rdata <- cbind(dataColonTest$status,ppoisGzero(index,calprob$h0))

rrAnalysisTest <- RRPlot(rdata,atThr = rrAnalysisCalTrain$thr_atP,
                     timetoEvent=dataColonTest$time,
                     title="Test: Colon Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=calprob$timeInterval)

```


### By Risk Categories
```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

obsexp <- rrAnalysisTest$OERatio$atThrEstimates

expObs(obsexp,"Test: Expected vs. Observed")

pander::pander(obsexp)

```



### Time to Event Analysis

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
rrAnalysisdata <- rrAnalysisTest

pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime,rrAnalysisdata$timetoEventData$expectedTime,paired = TRUE))
highrisk <- rrAnalysisdata$timetoEventData$class == 2
pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime[highrisk],rrAnalysisdata$timetoEventData$expectedTime[highrisk],paired = TRUE))

timesdata <- expObsTime(rrAnalysisdata,title="Test: Expected vs Observed")
pander::pander(timesdata)

```


### Test Performance

```{r results = "asis"}

pander::pander(t(rrAnalysisTest$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisTest$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisTest$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisTest$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisTest$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisTest$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisTest$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisTest$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisTest$thr_atP),caption="Probability Thresholds")
pander::pander(rrAnalysisTest$surdif,caption="Logrank test")

```

## Cross-Validation

Here we will cross validate the training set and evaluate also on the testing set.
The h0 and the timeinterval are the ones estimated on the calibration process

```{r results = "asis", warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

rcv <- randomCV(theData=dataColonTrain,
                theOutcome = Surv(time,status)~1,
                fittingFunction=BSWiMS.model, 
                trainFraction = 0.75,
                repetitions=50,
                classSamplingType = "Pro",
                testingSet=dataColonTest
         )


stp <- rcv$survTestPredictions
stp <- stp[!is.na(stp[,4]),]

bbx <- boxplot(unlist(stp[,1])~rownames(stp),plot=FALSE)
times <- bbx$stats[3,]
status <- boxplot(unlist(stp[,2])~rownames(stp),plot=FALSE)$stats[3,]
prob <- ppoisGzero(boxplot(unlist(stp[,4])~rownames(stp),plot=FALSE)$stats[3,],calprob$h0)

rdatacv <- cbind(status,prob)
rownames(rdatacv) <- bbx$names
names(times) <- bbx$names

rrAnalysisCVTest <- RRPlot(rdatacv,atThr = rrAnalysisCalTrain$thr_atP,
                     timetoEvent=times,
                     title="CV Test: Colon Cancer",
                     ysurvlim=c(0.00,1.0),
                     riskTimeInterval=calprob$timeInterval)

```


### By Risk Categories
```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}

obsexp <- rrAnalysisCVTest$OERatio$atThrEstimates

expObs(obsexp,"CV: Expected vs. Observed")

pander::pander(obsexp)

```



### Time to Event Analysis

```{r results = "asis",warning = FALSE , dpi=300, fig.height= 5.0, fig.width= 7.0}
rrAnalysisdata <- rrAnalysisCVTest

pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime,rrAnalysisdata$timetoEventData$expectedTime,paired = TRUE))
highrisk <- rrAnalysisdata$timetoEventData$class == 2
pander::pander(wilcox.test(rrAnalysisdata$timetoEventData$eTime[highrisk],rrAnalysisdata$timetoEventData$expectedTime[highrisk],paired = TRUE))

timesdata <- expObsTime(rrAnalysisdata,title="CV: Expected vs Observed")
pander::pander(timesdata)

```


### CV Test Performance

```{r results = "asis"}
pander::pander(t(rrAnalysisCVTest$keyPoints),caption="Threshold values")
pander::pander(t(rrAnalysisCVTest$OERatio$estimate),caption="O/E Ratio")
pander::pander(t(rrAnalysisCVTest$OE95ci),caption="O/E Mean")
pander::pander(t(rrAnalysisCVTest$OAcum95ci),caption="O/Acum Mean")
pander::pander(rrAnalysisCVTest$c.index$cstatCI,caption="C. Index")
pander::pander(t(rrAnalysisCVTest$ROCAnalysis$aucs),caption="ROC AUC")
pander::pander((rrAnalysisCVTest$ROCAnalysis$sensitivity),caption="Sensitivity")
pander::pander((rrAnalysisCVTest$ROCAnalysis$specificity),caption="Specificity")
pander::pander(t(rrAnalysisCVTest$thr_atP),caption="Probability Thresholds")
pander::pander(rrAnalysisCVTest$surdif,caption="Logrank test")

```

